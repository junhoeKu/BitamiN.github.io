{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4EaFcU2pny"
      },
      "source": [
        "문제 1. 텍스트 분석의 이해와 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50sAdbDm2pn1"
      },
      "source": [
        "(1) 빈칸에 알맞은 단어를 쓰세요.\n",
        "\n",
        "- 텍스트 분석 : (a) 데이터인 텍스트를 분석하는 것\n",
        "\n",
        "- 피처 벡터화 / 피처 추출 : 텍스트를 word 기반의 다수의 피처로 추출하고 이 피처에 단어 빈도수와 같은 숫자 값을 부여하여 텍스트를 단어의 조합인 (b)값으로 표현하는 것\n",
        "\n",
        "- (c) : 분석에 큰 의미가 없는 단어\n",
        "\n",
        "- Stemming과 Lemmatization : 문법적 또는 의미적으로 변화하는 단어의 (d)을 찾는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJkxf0G2pn1"
      },
      "source": [
        "[정답]\n",
        "\n",
        "(a) :\n",
        "\n",
        "(b) :\n",
        "\n",
        "(c) :\n",
        "\n",
        "(d) :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOFplakI2pn1"
      },
      "source": [
        "(2) 주어진 text_sample을 문장 토큰화 시켜주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zZlW_N32pn2"
      },
      "outputs": [],
      "source": [
        "from nltk import ##YOURCODE##\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text_sample = 'It is not enough to be in the right place at the right time.\\\n",
        "               You should also have an open mind at the right time.'\n",
        "sentences = ##YOURCODE##\n",
        "print(type(sentences),len(sentences))\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_BKoMwb2pn3"
      },
      "source": [
        "(3) 위에서 주어진 text_sample을 단어 토큰화 시켜주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPbht-9G2pn3"
      },
      "outputs": [],
      "source": [
        "from nltk import ##YOURCODE##\n",
        "\n",
        "words = ##YOURCODE##\n",
        "print(type(words),len(words))\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OT2pYFp2pn3"
      },
      "source": [
        "(4) 위에서 주어진 text_sample을 문장별로 나눈 후 개별 문장을 다시 단어로 토큰화 하는 함수를 만들어 적용하세요. 단, len(words)의 출력값이 2여야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xJt7Ei_2pn4"
      },
      "outputs": [],
      "source": [
        "#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n",
        "def tokenize_text(text):\n",
        "\n",
        "    # 문장별로 분리 토큰\n",
        "    sentences = sent_tokenize(text)\n",
        "    # 분리된 문장별 단어 토큰화\n",
        "    word_tokens = ##YOURCODE##\n",
        "    return word_tokens\n",
        "\n",
        "#여러 문장들에 대해 문장별 단어 토큰화 수행.\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqLlfnZb2pn4"
      },
      "source": [
        "(5) 위에서 얻은 word_tokens에서 스톱 워드를 제거해 주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFeV1QRb2pn4"
      },
      "outputs": [],
      "source": [
        "nltk.download(##YOURCODE##)\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n",
        "    for word in sentence:\n",
        "        #소문자로 모두 변환합니다.\n",
        "        word = word.lower()\n",
        "        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n",
        "        if word not in stopwords:\n",
        "            ##YOURCODE##\n",
        "    ##YOURCODE##\n",
        "\n",
        "print(all_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOmAZyIp2pn5"
      },
      "source": [
        "(6) 다음은 Stemming과 Lemmatization을 각각 이용하여 원형 단어를 찾는 과정입니다.\n",
        "\n",
        "코드를 완성하고 더 효과적이라고 생각하는 방법을 이용하여 'amazing'의 원형을 출력하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6Dkwz_g2pn5"
      },
      "outputs": [],
      "source": [
        "#Stemming\n",
        "from nltk.stem import ##YOURCODE##\n",
        "stemmer = ##YOURCODE##\n",
        "\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE8x4UJI2pn5"
      },
      "outputs": [],
      "source": [
        "#Lemmatization\n",
        "from nltk.stem import ##YOURCODE##\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemma = ##YOURCODE##\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trol8cjp2pn5"
      },
      "outputs": [],
      "source": [
        "#'amazing'의 원형 출력\n",
        "##YOURCODE##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwGKLmvw2sNN"
      },
      "source": [
        "문제 2 (Bag Of Words, BOW, 희소행렬)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOwsKzlB2tdm"
      },
      "source": [
        "2-1 </br>\n",
        "\n",
        "BOW는 문서가 가지는 모든 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델입니다. 이 모델의 단점 두 가지를 말해주세요 </br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbG3n6rl2uKV"
      },
      "source": [
        "1)\n",
        "</br>\n",
        "2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPuZPGlz2uNa"
      },
      "source": [
        "2-2</br>\n",
        "아래 코드를 실행해 카운트 기반의 피처 벡터화를 구현해 주세요.(단, 불용어로 and와 ,를 추가해 주세요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q6lNbS92uQu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"I like Pineapple and Pizza\",\n",
        "        \"The sun is shining brightly, and the birds are singing in the trees\",\n",
        "        \"I went to the store to buy groceries, and I also picked up some flowers for my friend\"]\n",
        "\n",
        "#CountVectorizer 객체 생성\n",
        "### Your Code ###\n",
        "#vocabulary 출력\n",
        "### your code ###\n",
        "#텍스트를 array로 변환\n",
        "### your code ###\n",
        "#array로 출력\n",
        "### your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t9TdZNR2uTh"
      },
      "source": [
        "2-3</br>\n",
        "아래 코드의 빈칸을 채워서 tf, D, df, idf, tf-idf계수, tf-idf행렬을 구해주세요(tf행렬은 2-2의 Countvector()를 사용해주세요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7pSAqlv2uV-"
      },
      "outputs": [],
      "source": [
        "tf =### your code ### #tf데이터 프레임\n",
        "D = ### your code ####D를 구해주세요\n",
        "df =### your code ###\n",
        "idf = ### your code ### #idf를 구해주세요\n",
        "\n",
        "tfidf =### your code ### #tf-idf계수를 구해주세요\n",
        "tfidf =### your code ### #tf-idf행렬을 구해주세요\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l0tTmju2uYm"
      },
      "source": [
        "2-4</br>\n",
        "아래 희소행렬을 COO 방식으로 출력해주세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpffHdio3Bay"
      },
      "outputs": [],
      "source": [
        "from scipy import sparse\n",
        "\n",
        "sparse_m = np.array([[0,1,0,0,0,4],\n",
        "             [1,4,0,0,2,5],\n",
        "             [0,1,0,3,0,0],\n",
        "             [1,0,4,0,5,0],\n",
        "             [0,0,0,0,0,8],\n",
        "             [1,0,0,0,7,0]])\n",
        "# 0 이 아닌 데이터 추출\n",
        "### your code ###\n",
        "\n",
        "# 행 위치와 열 위치를 각각 array로 생성\n",
        "### your code ###\n",
        "\n",
        "# COO 형식으로 변환\n",
        "### your code ###\n",
        "#COO 출력\n",
        "### your code ###\n",
        "#원본행렬 변환\n",
        "### your code ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70wcRvo_3BeV"
      },
      "source": [
        "2-5</br>\n",
        "2-5의 sparse_m 행렬을 CSR방식으로 관리하기 위한 행 위치 고유값을 말해주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBt9w2Q93Bhc"
      },
      "source": [
        "답)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 참고: 아래 문제는 3번 문제입니다!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 텍스트 분류 실습 - 20 뉴스그룹 분류 (총 10문제, 각 10점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset='all',random_state=156)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target 클래스의 값과 분포도 \n",
            " 0     799\n",
            "1     973\n",
            "2     985\n",
            "3     982\n",
            "4     963\n",
            "5     988\n",
            "6     975\n",
            "7     990\n",
            "8     996\n",
            "9     994\n",
            "10    999\n",
            "11    991\n",
            "12    984\n",
            "13    990\n",
            "14    987\n",
            "15    997\n",
            "16    910\n",
            "17    940\n",
            "18    775\n",
            "19    628\n",
            "dtype: int64\n",
            "target 클래스의 이름들 \n",
            " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index())\n",
        "print('target 클래스의 이름들 \\n',news_data.target_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-1. 학습용 데이터와 내용, 테스트 데이터와 내용만 추출하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "train_news = '''YOUR CODE'''\n",
        "y_train = '''YOUR CODE'''\n",
        "\n",
        "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "test_news= '''YOUR CODE'''\n",
        "X_test = '''YOUR CODE'''\n",
        "y_test = '''YOUR CODE'''\n",
        "\n",
        "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-2. 피처 벡터화 변환을 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorization으로 feature extraction 변환 수행.\n",
        "cnt_vect = '''YOUR CODE'''\n",
        "\n",
        "'''YOUR CODE'''\n",
        "X_train_cnt_vect = '''YOUR CODE'''\n",
        "\n",
        "# 학습 데이터로 fit( )된 CountVectorizer를 이용하여 테스트 데이터를 feature extraction 변환 수행.\n",
        "X_test_cnt_vect = '''YOUR CODE'''\n",
        "\n",
        "print('학습 데이터 Text의 CountVectorizer Shape:',X_train_cnt_vect.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-3. LogisticRegression을 이용하여 학습/예측/평가를 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LogisticRegression을 이용하여 학습/예측/평가 수행.\n",
        "lr_clf = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "pred = '''YOUR CODE'''\n",
        "\n",
        "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-4. TF_IDF 벡터화 변환을 수행하고, LogisticRegression을 이용해 학습/예측/평가를 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\n",
        "tfidf_vect = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "X_train_tfidf_vect = '''YOUR CODE'''\n",
        "X_test_tfidf_vect = '''YOUR CODE'''\n",
        "\n",
        "# LogisticRegression을 이용하여 학습/예측/평가 수행.\n",
        "lr_clf = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "pred = '''YOUR CODE'''\n",
        "\n",
        "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-5. stop words 필터링을 추가하여 벡터화 변환을 수행하고, LogisticRegression을 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경하여 Feature Vectorization 적용.\n",
        "tfidf_vect = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "X_train_tfidf_vect = '''YOUR CODE'''\n",
        "X_test_tfidf_vect = '''YOUR CODE'''\n",
        "\n",
        "lr_clf = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "pred = '''YOUR CODE'''\n",
        "\n",
        "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-6. GridSearchCV를 이용해 튜닝하고, LogisticRegression을 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정.\n",
        "params = '''YOUR CODE'''\n",
        "grid_cv_lr = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "print('Logistic Regression best C parameter :',grid_cv_lr.best_params_ )\n",
        "\n",
        "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가.\n",
        "pred = '''YOUR CODE'''\n",
        "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-7. TfidfVectorizer 객체를 `tfidf_vect` 객체명으로, LogisticRegression객체를 `lr_clf` 객체명으로 생성하는 Pipeline생성하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# TfidfVectorizer 객체를 tfidf_vect 객체명으로, LogisticRegression객체를 lr_clf 객체명으로 생성하는 Pipeline생성\n",
        "pipeline = '''YOUR CODE'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-8. Feature Vectorization과 ML 학습/예측을 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 별도의 TfidfVectorizer객체의 fit_transform( )과 LogisticRegression의 fit(), predict( )가 필요 없음.\n",
        "# pipeline의 fit( ) 과 predict( ) 만으로 한꺼번에 Feature Vectorization과 ML 학습/예측이 가능.\n",
        "'''YOUR CODE'''\n",
        "pred = '''YOUR CODE'''\n",
        "\n",
        "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-9. Pipeline을 통한 Logistic Regression을 수행하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression(solver='liblinear'))\n",
        "])\n",
        "\n",
        "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될\n",
        "# 파라미터/하이퍼 파라미터 이름과 값을 설정. .\n",
        "params = { 'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "           'tfidf_vect__max_df': [100, 300, 700],\n",
        "           'lr_clf__C': [1, 5, 10]\n",
        "}\n",
        "\n",
        "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
        "grid_cv_pipe = '''YOUR CODE'''\n",
        "'''YOUR CODE'''\n",
        "print(grid_cv_pipe.best_params_ , grid_cv_pipe.best_score_)\n",
        "\n",
        "pred = '''YOUR CODE'''\n",
        "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4-10. TfdifVectorizer 객체 변수명에 언더바 2개를 연달아 붙이는 이유를 서술하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "답:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
